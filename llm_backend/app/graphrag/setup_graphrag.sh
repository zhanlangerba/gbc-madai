#!/bin/bash

# GraphRAGçŽ¯å¢ƒè®¾ç½®è„šæœ¬
# ç”¨äºŽåœ¨æ²¡æœ‰é¢„æž„å»ºè™šæ‹ŸçŽ¯å¢ƒçš„æƒ…å†µä¸‹è®¾ç½®GraphRAGåŠŸèƒ½

echo "ðŸš€ å¼€å§‹è®¾ç½®GraphRAGçŽ¯å¢ƒ..."

# æ£€æŸ¥Pythonç‰ˆæœ¬
python_version=$(python3 --version 2>&1 | grep -oP '\d+\.\d+' | head -1)
required_version="3.8"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" != "$required_version" ]; then
    echo "âŒ é”™è¯¯: éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå½“å‰ç‰ˆæœ¬: $python_version"
    exit 1
fi

echo "âœ… Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: $python_version"

# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ
echo "ðŸ“¦ åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ..."
python3 -m venv venv

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
echo "ðŸ”„ æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ..."
source venv/bin/activate

# å‡çº§pip
echo "â¬†ï¸ å‡çº§pip..."
pip install --upgrade pip

# å®‰è£…GraphRAGæ ¸å¿ƒä¾èµ–
echo "ðŸ“š å®‰è£…GraphRAGä¾èµ–..."
pip install graphrag==0.3.0

# å®‰è£…æ•°æ®å¤„ç†ä¾èµ–
echo "ðŸ“Š å®‰è£…æ•°æ®å¤„ç†ä¾èµ–..."
pip install pandas numpy pyarrow

# å®‰è£…å‘é‡æ•°æ®åº“ä¾èµ–
echo "ðŸ” å®‰è£…å‘é‡æ•°æ®åº“ä¾èµ–..."
pip install lancedb

# å®‰è£…æœºå™¨å­¦ä¹ ä¾èµ–
echo "ðŸ¤– å®‰è£…æœºå™¨å­¦ä¹ ä¾èµ–..."
pip install scikit-learn

# å®‰è£…æ–‡æœ¬å¤„ç†ä¾èµ–
echo "ðŸ“ å®‰è£…æ–‡æœ¬å¤„ç†ä¾èµ–..."
pip install nltk spacy

# åˆ›å»ºGraphRAGé…ç½®ç›®å½•
echo "ðŸ“ åˆ›å»ºé…ç½®ç›®å½•..."
mkdir -p data
mkdir -p output
mkdir -p cache

# åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
echo "âš™ï¸ åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶..."
cat > settings.yaml << 'EOF'
# GraphRAGé…ç½®æ–‡ä»¶ç¤ºä¾‹
# è¯·æ ¹æ®å®žé™…éœ€æ±‚ä¿®æ”¹

encoding_model: cl100k_base
skip_workflows: []
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: openai_chat
  model: ${GRAPHRAG_MODEL_NAME:gpt-4o-mini}
  model_supports_json: true
  max_tokens: 4000
  temperature: 0
  top_p: 1

parallelization:
  stagger: 0.3
  num_threads: 50

async_mode: threaded

embeddings:
  async_mode: threaded
  llm:
    api_key: ${Embedding_API_KEY}
    type: openai_embedding
    model: ${Embedding_MODEL_NAME:text-embedding-3-small}
    max_tokens: 8191

input:
  type: file
  file_type: text
  base_dir: "data"
  file_encoding: utf-8
  file_pattern: ".*\\.txt$"

cache:
  type: file
  base_dir: "cache"

storage:
  type: file
  base_dir: "output"

chunk:
  size: 300
  overlap: 100
  group_by_columns: [id]

entity_extraction:
  prompt: "prompts/entity_extraction.txt"
  entity_types: [organization,person,geo,event]
  max_gleanings: 0

summarize_descriptions:
  prompt: "prompts/summarize_descriptions.txt"
  max_length: 500

claim_extraction:
  prompt: "prompts/claim_extraction.txt"
  description: "Any claims or facts that could be relevant to information discovery."
  max_gleanings: 0

community_report:
  prompt: "prompts/community_report.txt"
  max_length: 2000
  max_input_length: 8000

cluster_graph:
  max_cluster_size: 10

embed_graph:
  enabled: false

umap:
  enabled: false

snapshots:
  graphml: false
  raw_entities: false
  top_level_nodes: false

local_search:
  text_unit_prop: 0.5
  community_prop: 0.1
  conversation_history_max_turns: 5
  top_k_mapped_entities: 10
  top_k_relationships: 10
  max_tokens: 12000

global_search:
  max_tokens: 12000
  data_max_tokens: 12000
  map_max_tokens: 1000
  reduce_max_tokens: 2000
  concurrency: 32
EOF

echo "âœ… GraphRAGçŽ¯å¢ƒè®¾ç½®å®Œæˆï¼"
echo ""
echo "ðŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œï¼š"
echo "1. é…ç½®çŽ¯å¢ƒå˜é‡ (.env æ–‡ä»¶):"
echo "   GRAPHRAG_API_KEY=your-api-key"
echo "   GRAPHRAG_MODEL_NAME=gpt-4o-mini"
echo "   Embedding_API_KEY=your-embedding-key"
echo "   Embedding_MODEL_NAME=text-embedding-3-small"
echo ""
echo "2. å°†æ–‡æœ¬æ–‡ä»¶æ”¾å…¥ data/ ç›®å½•"
echo "3. è¿è¡Œç´¢å¼•æž„å»º: python -m graphrag.index --root ."
echo "4. è¿è¡ŒæŸ¥è¯¢: python -m graphrag.query --root . --method local \"your question\""
echo ""
echo "ðŸ”— æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ: https://github.com/microsoft/graphrag"
